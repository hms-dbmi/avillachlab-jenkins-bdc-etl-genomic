<?xml version='1.1' encoding='UTF-8'?>
<flow-definition plugin="workflow-job@2.35">
  <actions>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobAction plugin="pipeline-model-definition@1.3.9"/>
    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction plugin="pipeline-model-definition@1.3.9">
      <jobProperties/>
      <triggers/>
      <parameters/>
      <options/>
    </org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction>
  </actions>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <definition class="org.jenkinsci.plugins.workflow.cps.CpsFlowDefinition" plugin="workflow-cps@2.74">
    <script>pipeline {
 
  agent any 
  
  
  environment {
     def BUILD_TIMESTAMP = sh(script: &quot;echo `date +%Y%m%d%H%M%S`&quot;, returnStdout: true).trim()
     def AUTHSCHEMA_IMAGE_NAME  = &quot;picsure-db-migration-authschema-image&quot;  
     def CONTAINER_NAME=&quot;main_authschema_orchestrator_container&quot; 
     
     def jsonObj = readJSON file: &apos;/cic-config.json&apos; 
     def S3_PROFILE_NAME  = sh(script: &quot;echo ${jsonObj.s3_profiles.datastage_prod.s3_profile_name}&quot;, returnStdout:true).trim().replaceAll(&quot;\\[|\\]&quot;, &quot;&quot;)
     def S3_BUCKET_NAME  = sh(script: &quot;echo ${jsonObj.s3_profiles.datastage_prod.s3_bucket_name}&quot;, returnStdout:true).trim().replaceAll(&quot;\\[|\\]&quot;, &quot;&quot;)
     def S3_BUCKET_PROPERTIES_FILE_NAME  = sh(script: &quot;echo ${jsonObj.s3_profiles.datastage_prod.s3_bucket_properties_file_name}&quot;, returnStdout:true).trim().replaceAll(&quot;\\[|\\]&quot;, &quot;&quot;)
      
  }   
  
  stages { 
    stage(&apos;Prechecks&apos;){ 
        steps {
            sh &apos;aws s3 ls  --profile $S3_PROFILE_NAME&apos;
        } 
    }   
    
    stage(&apos;Copy Image from S3 to Local&apos;){ 
        steps {
            sh &apos;&apos;&apos;
            	aws s3 cp s3://$S3_BUCKET_NAME/$AUTHSCHEMA_IMAGE_NAME\&quot;.tar.gz\&quot; . --profile $S3_PROFILE_NAME 
            &apos;&apos;&apos;
        } 
    }
     
    stage(&apos;Load Docker Image&apos;){ 
        steps {
            sh &apos;&apos;&apos; 
            	docker load &lt; $AUTHSCHEMA_IMAGE_NAME\&quot;.tar.gz\&quot;
			&apos;&apos;&apos;
        } 
    }
    
    stage(&apos;Clean and Start the Container&apos;){ 
        steps {   
        	 sh &apos;&apos;&apos; 
				CONTAINER_FOUND=&quot;$(docker ps --all --quiet --filter=name=&quot;$CONTAINER_NAME&quot;)&quot;
				if [ -n &quot;$CONTAINER_FOUND&quot; ]; then
  					docker stop $CONTAINER_FOUND &amp;&amp; docker rm $CONTAINER_FOUND
				fi 
			&apos;&apos;&apos; 

			sh &apos;&apos;&apos;
				docker run --name $CONTAINER_NAME  -d --entrypoint /usr/bin/python3  dbmi/picsure-db-migrations:$AUTHSCHEMA_IMAGE_NAME /app/index.py
				
			&apos;&apos;&apos;
			
            sleep(time:15,unit:&quot;SECONDS&quot;)
        } 
    }
      
    stage(&apos;Run DB Migration&apos;){ 
        steps {  
        	 sh &apos;&apos;&apos;
        	 	docker exec -i $CONTAINER_NAME bash -c \&quot;/picsure-db-migrations/scripts/main/auth/auth-migration-orchestrator.sh\&quot;
			&apos;&apos;&apos;  
        } 
    }     
    
    stage(&apos;Clean up resources&apos;){ 
        steps {  
        	 sh &apos;&apos;&apos;
        	 	CONTAINER_NAME=$CONTAINER_NAME
				CONTAINER_FOUND=&quot;$(docker ps --all --quiet --filter=name=&quot;$CONTAINER_NAME&quot;)&quot;
				if [ -n &quot;$CONTAINER_FOUND&quot; ]; then
  					docker stop $CONTAINER_FOUND &amp;&amp; docker rm $CONTAINER_FOUND
				fi 
			&apos;&apos;&apos; 

        } 
    }    
    
         
     
  }
  
  post { 
        always { 
            cleanWs()
        }
  }
  
}</script>
    <sandbox>true</sandbox>
  </definition>
  <triggers/>
  <disabled>false</disabled>
</flow-definition>